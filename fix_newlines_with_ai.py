#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ DeepSeek API ä¿®å¤ CSV æ–‡ä»¶ä¸­è¯‘æ–‡çš„æ¢è¡Œç¬¦æ•°é‡ï¼Œä½¿å…¶ä¸åŸæ–‡ä¸€è‡´
"""

import csv
import os
import time
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    base_url=os.getenv('OPENAI_BASE_URL')
)


def count_newlines(text):
    """è®¡ç®—å­—ç¬¦ä¸²ä¸­\nçš„æ•°é‡"""
    if text is None:
        return 0
    return text.count('\\n')


def fix_translation_newlines(original_text, translated_text, target_newline_count):
    """ä½¿ç”¨ AI ä¿®å¤è¯‘æ–‡ä¸­çš„æ¢è¡Œç¬¦"""
    
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—¥è¯­åˆ°ä¸­æ–‡ç¿»è¯‘æ ¡å¯¹ä¸“å®¶ã€‚

åŸæ–‡ï¼ˆæ—¥è¯­ï¼‰åŒ…å« {target_newline_count} ä¸ªæ¢è¡Œç¬¦ï¼ˆ\\nï¼‰ï¼š
{original_text}

å½“å‰è¯‘æ–‡ï¼ˆä¸­æ–‡ï¼‰åŒ…å« {count_newlines(translated_text)} ä¸ªæ¢è¡Œç¬¦ï¼ˆ\\nï¼‰ï¼š
{translated_text}

è¯·åœ¨è¯‘æ–‡ä¸­æ·»åŠ æˆ–è°ƒæ•´æ¢è¡Œç¬¦ï¼ˆ\\nï¼‰ï¼Œä½¿è¯‘æ–‡çš„æ¢è¡Œç¬¦æ•°é‡ä¸åŸæ–‡ç›¸åŒï¼ˆ{target_newline_count} ä¸ªï¼‰ã€‚

è¦æ±‚ï¼š
1. è¯‘æ–‡å¿…é¡»åŒ…å«æ°å¥½ {target_newline_count} ä¸ª \\n
2. æ¢è¡Œä½ç½®è¦ç¬¦åˆä¸­æ–‡è¯­ä¹‰ï¼Œä¸èƒ½åˆ‡æ–­è¯è¯­æˆ–çŸ­è¯­
3. \\n ä¸èƒ½æ”¾åœ¨å¥å­çš„å¼€å¤´æˆ–ç»“å°¾
4. ä¿æŒè¯‘æ–‡çš„å®Œæ•´æ€§å’Œæµç•…æ€§
5. åªè¿”å›ä¿®æ­£åçš„è¯‘æ–‡ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Š

ä¿®æ­£åçš„è¯‘æ–‡ï¼š"""

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘æ ¡å¯¹ä¸“å®¶ï¼Œæ“…é•¿å¤„ç†æ–‡æœ¬æ ¼å¼ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )
        
        fixed_text = response.choices[0].message.content.strip()
        
        # éªŒè¯ä¿®æ­£åçš„æ¢è¡Œç¬¦æ•°é‡
        fixed_count = count_newlines(fixed_text)
        if fixed_count == target_newline_count:
            return fixed_text, True
        else:
            print(f"  âš ï¸  AI ä¿®æ­£åçš„æ¢è¡Œç¬¦æ•°é‡ä¸åŒ¹é…: æœŸæœ› {target_newline_count}, å®é™… {fixed_count}")
            return translated_text, False
            
    except Exception as e:
        print(f"  âŒ API è°ƒç”¨å¤±è´¥: {e}")
        return translated_text, False


def check_and_fix_csv_file(file_path, dry_run=False):
    """æ£€æŸ¥å¹¶ä¿®å¤å•ä¸ª CSV æ–‡ä»¶"""
    mismatches = []
    rows = []
    
    try:
        # è¯»å–æ‰€æœ‰è¡Œ
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            header = next(reader)
            rows.append(header)
            
            for row_num, row in enumerate(reader, start=2):
                rows.append(row)
                
                if len(row) < 4:
                    continue
                
                id_val = row[0]
                name_val = row[1]
                text_col = row[2]  # ç¬¬ä¸‰åˆ—ï¼ˆåŸæ–‡ï¼‰
                trans_col = row[3]  # ç¬¬å››åˆ—ï¼ˆè¯‘æ–‡ï¼‰
                
                text_newline_count = count_newlines(text_col)
                trans_newline_count = count_newlines(trans_col)
                
                if text_newline_count != trans_newline_count:
                    mismatches.append({
                        'row_index': len(rows) - 1,
                        'row_num': row_num,
                        'id': id_val,
                        'name': name_val,
                        'text': text_col,
                        'trans': trans_col,
                        'text_count': text_newline_count,
                        'trans_count': trans_newline_count
                    })
    
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return 0, 0
    
    if not mismatches:
        return 0, 0
    
    print(f"\nğŸ“„ æ–‡ä»¶: {file_path.name}")
    print(f"   å‘ç° {len(mismatches)} å¤„ä¸ä¸€è‡´")
    
    fixed_count = 0
    
    # ä¿®å¤æ¯ä¸ªä¸ä¸€è‡´çš„åœ°æ–¹
    for i, mismatch in enumerate(mismatches, 1):
        print(f"\n   [{i}/{len(mismatches)}] è¡Œ {mismatch['row_num']}: {mismatch['name']}")
        print(f"   åŸæ–‡ ({mismatch['text_count']}ä¸ª\\n): {mismatch['text'][:50]}...")
        print(f"   è¯‘æ–‡ ({mismatch['trans_count']}ä¸ª\\n): {mismatch['trans'][:50]}...")
        
        if not dry_run:
            # è°ƒç”¨ AI ä¿®å¤
            fixed_text, success = fix_translation_newlines(
                mismatch['text'],
                mismatch['trans'],
                mismatch['text_count']
            )
            
            if success:
                # æ›´æ–°è¡Œæ•°æ®
                rows[mismatch['row_index']][3] = fixed_text
                fixed_count += 1
                print(f"   âœ… å·²ä¿®å¤: {fixed_text[:50]}...")
            
            # æ·»åŠ å»¶è¿Ÿä»¥é¿å… API é™æµ
            time.sleep(0.5)
    
    # å†™å›æ–‡ä»¶ï¼ˆå¦‚æœä¸æ˜¯ dry runï¼‰
    if not dry_run and fixed_count > 0:
        try:
            with open(file_path, 'w', encoding='utf-8', newline='') as f:
                writer = csv.writer(f)
                writer.writerows(rows)
            print(f"\n   ğŸ’¾ å·²ä¿å­˜ {fixed_count} å¤„ä¿®å¤åˆ°æ–‡ä»¶")
        except Exception as e:
            print(f"\n   âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            return len(mismatches), 0
    
    return len(mismatches), fixed_count


def main():
    print("=" * 80)
    print("ä½¿ç”¨ DeepSeek AI ä¿®å¤è¯‘æ–‡æ¢è¡Œç¬¦")
    print("=" * 80)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv('OPENAI_API_KEY') or not os.getenv('OPENAI_BASE_URL'):
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° OPENAI_API_KEY æˆ– OPENAI_BASE_URL ç¯å¢ƒå˜é‡")
        print("è¯·ç¡®ä¿ .env æ–‡ä»¶å­˜åœ¨å¹¶åŒ…å«è¿™äº›é…ç½®")
        return
    
    print(f"\nâœ… API é…ç½®å·²åŠ è½½")
    print(f"   Base URL: {os.getenv('OPENAI_BASE_URL')}")
    
    # è¯¢é—®æ˜¯å¦æµ‹è¯•è¿è¡Œ
    choice = input("\næ˜¯å¦è¿›è¡Œæµ‹è¯•è¿è¡Œï¼ˆåªæ£€æŸ¥ä¸ä¿®æ”¹ï¼‰? [y/N]: ").strip().lower()
    dry_run = (choice == 'y')
    
    if dry_run:
        print("\nâš ï¸  æµ‹è¯•æ¨¡å¼ï¼šå°†æ£€æŸ¥æ–‡ä»¶ä½†ä¸ä¼šè¿›è¡Œä¿®æ”¹")
    else:
        print("\nâš ï¸  ç”Ÿäº§æ¨¡å¼ï¼šå°†ä¿®æ”¹æ–‡ä»¶å†…å®¹")
        confirm = input("ç¡®è®¤ç»§ç»­? [y/N]: ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆ")
            return
    
    # è·å– data ç›®å½•ä¸‹çš„æ‰€æœ‰ CSV æ–‡ä»¶
    data_dir = Path('data')
    
    if not data_dir.exists():
        print("âŒ é”™è¯¯: data ç›®å½•ä¸å­˜åœ¨")
        return
    
    csv_files = list(data_dir.glob('*.csv'))
    
    if not csv_files:
        print("âŒ é”™è¯¯: data ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ° CSV æ–‡ä»¶")
        return
    
    print(f"\næ‰¾åˆ° {len(csv_files)} ä¸ª CSV æ–‡ä»¶")
    print("=" * 80)
    
    total_mismatches = 0
    total_fixed = 0
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for csv_file in sorted(csv_files):
        mismatches, fixed = check_and_fix_csv_file(csv_file, dry_run)
        total_mismatches += mismatches
        total_fixed += fixed
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("å¤„ç†å®Œæˆï¼")
    print("=" * 80)
    print(f"å…±æ£€æŸ¥ {len(csv_files)} ä¸ªæ–‡ä»¶")
    print(f"å‘ç° {total_mismatches} å¤„æ¢è¡Œç¬¦ä¸ä¸€è‡´")
    
    if not dry_run:
        print(f"æˆåŠŸä¿®å¤ {total_fixed} å¤„")
        if total_fixed < total_mismatches:
            print(f"æœªèƒ½ä¿®å¤ {total_mismatches - total_fixed} å¤„ï¼ˆéœ€è¦äººå·¥æ£€æŸ¥ï¼‰")


if __name__ == '__main__':
    main()
